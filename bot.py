# bot.py

import os
import sys
import asyncio
import logging
import json

USAGE_FILE = "usage.json"

def load_usage():
    if os.path.exists(USAGE_FILE):
        with open(USAGE_FILE, "r") as f:
            return json.load(f)
    return {}

def save_usage(usage):
    with open(USAGE_FILE, "w") as f:
        json.dump(usage, f)


from dotenv import load_dotenv
import openai

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ConversationHandler,
    ContextTypes,
    filters,
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–æ–±—ã—Ç–∏–π–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –Ω–∞ Windows
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
TOKEN = os.getenv("TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
GENERATE_DESCRIPTION = 1

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É /generate –∏ –≤–≤–µ–¥–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏.")

# –ö–æ–º–∞–Ω–¥–∞ /generate
async def generate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ß—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å? –ù–∞–ø–∏—à–∏ –æ–ø–∏—Å–∞–Ω–∏–µ:")
    return GENERATE_DESCRIPTION

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞-–ø–æ–¥—Å–∫–∞–∑–∫–∏
async def handle_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.effective_user.id)
    prompt = update.message.text

    usage = load_usage()
    user_usage = usage.get(user_id, {"count": 0, "limit": 5})

    if user_usage["count"] >= user_usage["limit"]:
        await update.message.reply_text(
            "‚ùó –¢—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≤—Å–µ 5 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–π.\n\n"
            "üëâ –•–æ—á–µ—à—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å? –û–ø–ª–∞—Ç–∏ 500‚ÇΩ –∑–∞ 100 –≥–µ–Ω–µ—Ä–∞—Ü–∏–π."
        )
        return -1  # –ó–∞–≤–µ—Ä—à–∞–µ–º –¥–∏–∞–ª–æ–≥

    await update.message.reply_text("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø–æ–¥–æ–∂–¥–∏ 10‚Äì15 —Å–µ–∫—É–Ω–¥...")

    try:
        response = openai.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024",
            quality="standard",
        )
        image_url = response.data[0].url
        await update.message.reply_photo(photo=image_url, caption="–ì–æ—Ç–æ–≤–æ!")

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
        user_usage["count"] += 1
        usage[user_id] = user_usage
        save_usage(usage)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

    return -1  # –ó–∞–≤–µ—Ä—à–∞–µ–º –¥–∏–∞–ª–æ–≥

# –ö–æ–º–∞–Ω–¥–∞ –æ—Ç–º–µ–Ω—ã
async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–û—Ç–º–µ–Ω–µ–Ω–æ.")
    return ConversationHandler.END

# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
def main():
    app = ApplicationBuilder().token(TOKEN).build()

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∏–∞–ª–æ–≥–∞
    conversation = ConversationHandler(
        entry_points=[CommandHandler("generate", generate)],
        states={
            GENERATE_DESCRIPTION: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_prompt)],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    app.add_handler(CommandHandler("start", start))
    app.add_handler(conversation)

    # –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ polling
    app.run_polling()

if __name__ == "__main__":
    main()


